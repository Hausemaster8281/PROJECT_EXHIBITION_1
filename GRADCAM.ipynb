{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176a45a6-07ca-4dfb-814f-85bd2ec973e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision  # Add this import\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2f32e5-5a8a-40df-9556-f47216314e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Grad-CAM class (as defined earlier)\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        # Hook for gradients\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0]\n",
    "\n",
    "        # Hook for forward activations\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate_cam(self, input_tensor, target_class=None):\n",
    "        self.model.eval()\n",
    "\n",
    "        # Forward pass to get outputs\n",
    "        output = self.model(input_tensor)\n",
    "        if target_class is None:\n",
    "            target_class = torch.argmax(output)\n",
    "\n",
    "        # Backpropagate gradients for the target class\n",
    "        self.model.zero_grad()\n",
    "        output[:, target_class].backward()\n",
    "\n",
    "        # Compute the Grad-CAM\n",
    "        gradients = self.gradients.detach().cpu().numpy()  # Detach gradients before converting\n",
    "        activations = self.activations.detach().cpu().numpy()  # Detach activations before converting\n",
    "        weights = np.mean(gradients, axis=(2, 3))  # Global average pooling\n",
    "        cam = np.zeros(activations.shape[2:], dtype=np.float32)\n",
    "        for i, w in enumerate(weights[0]):\n",
    "            cam += w * activations[0, i]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, (224, 224))\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min())  # Normalize\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7920c069-0af7-4a6d-ad7b-b1004bc7dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function (same as before)\n",
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3d9ccb-e6d8-4480-98b0-9087381148a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model architecture and weights\n",
    "def load_model(model_path):\n",
    "    # Define the model architecture here\n",
    "    model = torchvision.models.vgg16(pretrained=False)  # Example: VGG16\n",
    "    model.classifier[6] = nn.Linear(in_features=4096, out_features=2)  # Adjust the last layer for binary classification\n",
    "\n",
    "    # Load the saved model weights\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357d420e-3415-4939-91b5-09a09e2f9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict and generate heatmap (same as before)\n",
    "def predict_and_generate_heatmap(model, image_path, target_layer):\n",
    "    input_tensor = preprocess_image(image_path).to(device)\n",
    "    \n",
    "    # Initialize Grad-CAM\n",
    "    gradcam = GradCAM(model=model, target_layer=target_layer)\n",
    "\n",
    "    # Generate the heatmap\n",
    "    cam = gradcam.generate_cam(input_tensor)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_label = \"Infected\" if predicted.item() == 1 else \"Uninfected\"\n",
    "\n",
    "    # Visualize the heatmap\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Show original image with prediction label\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Original Image\\nPredicted: {predicted_label}\")\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Show Grad-CAM heatmap with prediction label\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Grad-CAM Heatmap\\nPredicted: {predicted_label}\")\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cb7772-df76-4380-92cf-44eb411c4b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Set device\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Load the model (make sure the path is correct)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancer_model_full_dataset.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to your saved model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the model (make sure the path is correct)\n",
    "    model_path = \"cancer_model_full_dataset.pth\"  # Path to your saved model\n",
    "    model = load_model(model_path).to(device)\n",
    "\n",
    "    # Example usage\n",
    "    image_path = \"Demo/Inf/image_0_1.tif\"  # Path to the image you want to classify\n",
    "    target_layer = model.features[29]  # Set the target layer for Grad-CAM\n",
    "    predict_and_generate_heatmap(model, image_path, target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8505c-7106-4e47-9bf4-6f55bef8e7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
